<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="DexGraspAnything: Towards Universal Robotic Dexterous Grasping with Physics Awareness">
  <meta property="og:title" content="DexGraspAnything: Universal Robotic Dexterous Grasping">
  <meta property="og:description" content="A method for universal robotic dexterous grasping with physics awareness. CVPR 2025.">
  <meta property="og:image" content="static/images/teaser.png">
  <meta property="og:url" content="https://your-website-url.com">
  <title>DexGraspAnything</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>
<body>
  <section class="hero is-primary">
    <div class="hero-body">
      <div class="container">
        <h1 class="title">DexGraspAnything</h1>
        <h2 class="subtitle">Towards Universal Robotic Dexterous Grasping with Physics Awareness</h2>
        <div class="columns is-mobile">
          <div class="column">
            <p class="author-block">Yiming Zhong<sup>*</sup></p>
            <p class="author-block">Qi Jiang<sup>*</sup></p>
            <p class="author-block">Jingyi Yu</p>
            <p class="author-block">Yuexin Ma<sup>+</sup></p>
            <p class="author-block">ShanghaiTech University, Shanghai, China</p>
            <p class="author-block"><small><sup>*</sup>Equal Contribution | <sup>+</sup>Corresponding Author</small></p>
          </div>
          <div class="column">
            <a href="https://arxiv.org/pdf/2412.01550" target="_blank" class="button is-light">Paper</a>
            <a href="https://github.com/4DVLab/DexGrasp-Anything" target="_blank" class="button is-light">Code</a>
            <a href="https://arxiv.org/abs/2412.01550" target="_blank" class="button is-light">Dataset</a>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title">Abstract</h2>
      <p>
        A dexterous hand capable of grasping any object is essential for the development of general-purpose embodied intelligent robots. However, due to the high degree of freedom in dexterous hands and the vast diversity of objects, generating high-quality, usable grasping poses in a robust manner is a significant challenge. In this paper, we introduce DexGrasp Anything, a method that effectively integrates physical constraints into both the training and sampling phases of a diffusion-based generative model, achieving state-of-the-art performance across nearly all open datasets. Additionally, we present a new dexterous grasping dataset containing over 3.4 million diverse grasping poses for more than 15k different objects, demonstrating its potential to advance universal dexterous grasping.
      </p>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title">Teaser</h2>
      <div class="columns">
        <div class="column">
          <img src="static/images/teaser.png" alt="Teaser Image">
        </div>
        <div class="column">
          <p>
            DexGrasp Anything consistently surpasses previous dexterous grasping generation methods across five benchmarks. Visualization of our method's results is shown above.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title">Highlights</h2>
      <ul>
        <li>Physics-aware diffusion generator for dexterous grasping pose generation.</li>
        <li>State-of-the-art performance on five dexterous grasping datasets.</li>
        <li>New dataset with over 3.4 million grasping poses for more than 15k objects.</li>
      </ul>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{zhong2025dexgraspanything,
  title={DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with Physics Awareness},
  author={Zhong, Yiming and Jiang, Qi and Yu, Jingyi and Ma, Yuexin},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2025}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="content has-text-centered">
      <p>
        This project page is built using a custom template. You can find the source code <a href="https://github.com/your-repo" target="_blank">here</a>.
      </p>
    </div>
  </footer>
</body>
</html>